---
title: "Differential Abundance Analysis TimeCourse"
author: "Simon Haugaard & Ali Altıntaş"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_collapsed: true
    toc_depth: 3
    number_sections: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Required R libraries
```{r library}
if (!require("pacman")) install.packages("pacman")
pacman::p_load("edgeR", "readr", "readxl", "biomaRt", "magrittr", "tibble", "stringr", 
               "ggplot2", "data.table", "patchwork", "openxlsx", "dplyr", "missForest", 
               "RColorBrewer", "limma", "DEqMS", "preprocessCore", "DEP", 
               "SummarizedExperiment", "Metrics", "fdrtool", "aamisc", "sva")

# install aamisc package for MDS and Volcano plots
# Commented out for future use:
# pacman::p_load("qvalue", "rain", "limma", "devtools")
# url <- "https://cran.r-project.org/src/contrib/Archive/HarmonicRegression/HarmonicRegression_1.0.tar.gz"
# pkgFile <- "HarmonicRegression_1.0.tar.gz"
# download.file(url = url, destfile = pkgFile)
# install.packages(pkgs=pkgFile, type="source", repos=NULL)
# file.remove(pkgFile)
# pacman::p_load_gh("altintasali/aamisc")

# Colours for publication
publication_colors <- c("Control" = "#285291", "Metformin" = "#7C1516", "Sham" = "#9B9B9B")

```

# Read data and filtrer
```{r read_data}
# Load count data from a local file and metadata through Excel
# Define file paths
count_file <- "../../../data/count/report.unique_genes_matrix.tsv"
meta_file <- "../../../data/metadata/meta_proteomics.xlsx"
geneinfo_file <- "../../../data/gene_annotation/horse_gene_annotation.tsv.gz"

# Read count data
count <- readr::read_delim(count_file)

# Read metadata
meta <- readxl::read_excel(meta_file)

# Remove unnecessary or blank columns from MS machine
count <- count %>% select(-matches("D:\\\\Mass_spectrometry\\\\Raw_data\\\\Joakim\\\\Simon Horse second run2\\\\10A_RA11_1_24830.d"))

# Read and clean gene annotation file
geneinfo <- fread(geneinfo_file)
setnames(geneinfo, old = names(geneinfo), new = c("ENSEMBL", "ENSEMBLv", "Description_detailed", 
                                                  "Chr", "Start", "End", "Strand", "GENENAME", "ENTREZID", "Description"))
geneinfo <- geneinfo %>% select(-ENSEMBLv, -Description_detailed) %>% distinct(ENSEMBL, .keep_all = TRUE)

# Merge gene annotation with count data
annot <- merge(count[, "Genes", drop = FALSE], geneinfo, by.x = "Genes", by.y = "GENENAME", all.x = TRUE)

# Clean count data
count <- count %>% remove_rownames() %>% column_to_rownames(var="Genes")
cleaned_names <- gsub("D:\\\\Mass_spectrometry\\\\Raw_data\\\\Joakim\\\\Simon Horse second run2\\\\|_.*", "", colnames(count))
colnames(count) <- cleaned_names
meta$`Sample ID` <- cleaned_names

#subset data to only RA terminal and baseline samples
meta <- meta[meta$Region %in% c("RA"), ]
count <- count[, colnames(count) %in% meta$`Sample ID`]


# Remove low count samples from Count and Meta
samples_to_remove <- c("25C", "12A", "22A", "19A")
count <- count[, !colnames(count) %in% samples_to_remove]
meta <- meta %>% filter(!`Sample ID` %in% samples_to_remove)

# Calculate the number of proteins in each sample
num_proteins <- colSums(!is.na(count))
num_proteins <- num_proteins[meta$`Sample ID`]  # Ensure matching order with meta

# Define color scheme for groups
KUalt <- c("#7C1516", "#285291", "#434343", "#999999")  # Custom color palette
group_colors <- setNames(KUalt[1:length(unique(meta$Group))], unique(meta$Group))
bar_colors <- group_colors[meta$Group]

# Plot the number of proteins in each sample before filtering
par(mfrow = c(1, 1))
barplot(num_proteins, 
        main = "Number of Proteins in Each Sample\nBefore Filtering",
        xlab = "Sample",
        ylab = "Number of Proteins",
        col = bar_colors,
        border = "black",
        ylim = c(0, 2500),
        las = 2)

# Print the total number of proteins before filtering
cat("The total number of proteins before filtering was", max(num_proteins), "\n")

# Identify genes with less than three valid values in any condition
invalid_genes <- unique(unlist(lapply(unique(meta$Condition), function(condition) {
  condition_columns <- meta$`Sample ID`[meta$Condition == condition]
  condition_count <- count[, condition_columns, drop = FALSE]
  rownames(condition_count)[rowSums(!is.na(condition_count)) < 3]
})))

# Remove invalid genes from the original count table
filtered_count <- count[!rownames(count) %in% invalid_genes, ]

# Calculate the number of proteins in each sample after filtering
num_proteins_after <- colSums(!is.na(filtered_count))
num_proteins_after <- num_proteins_after[meta$`Sample ID`]  # Ensure matching order with meta

# Plot settings
par(mfrow = c(1, 2))

# First plot: Number of proteins in each sample before filtering
barplot(num_proteins, 
        main = "Number of Proteins in Each Sample\nBefore Filtering",
        xlab = "Sample",
        ylab = "Number of Proteins",
        col = bar_colors,
        border = "black",
        ylim = c(0, 2500),
        las = 2)

# Second plot: Number of proteins in each sample after filtering
barplot(num_proteins_after, 
        main = "Number of Proteins in Each Sample\nAfter Filtering",
        xlab = "Sample",
        ylab = "Number of Proteins",
        col = bar_colors,
        border = "black",
        ylim = c(0, 2500),
        las = 2)

# Print the total and average number of proteins before and after filtering
cat("The total number of proteins before filtering was", max(num_proteins), "\n")
cat("The average number of proteins before filtering was", mean(num_proteins), "\n")
cat("The total number of proteins after filtering was", max(num_proteins_after), "\n")
cat("The average number of proteins after filtering was", mean(num_proteins_after), "\n")
```
# DEP-package  https://bioconductor.org/packages/release/bioc/vignettes/DEP/inst/doc/DEP.html
## Generate a SummarizedExperiment object
```{r DEP - create SE object}
# Generate proxy columns similar to DEP's sample data to make the structure compatible.
proxy_column_names <- c("Protein.IDs", "Majority.protein.IDs", "Protein.names", "Gene.names", 
                        "Fasta.headers", "Peptides", "Razor...unique.peptides", "Unique.peptides", 
                        "Only.identified.by.site", "Reverse", "Potential.contaminant")
proxy_df <- data.frame(matrix(NA, nrow=nrow(filtered_count), ncol=length(proxy_column_names)))
colnames(proxy_df) <- proxy_column_names

# Assign row names to specific columns
rownames_to_columns <- rownames(filtered_count)
proxy_df[1:4] <- lapply(1:4, function(i) rownames_to_columns)

# Merge and rename sample columns
merged_df <- cbind(proxy_df, filtered_count)
colnames(merged_df)[12:ncol(merged_df)] <- paste0("LFQ.intensity.", colnames(filtered_count))

# Reorder columns
lfq_columns <- grep("^LFQ.intensity", colnames(merged_df), value = TRUE)
new_order <- c(proxy_column_names[1:8], lfq_columns, proxy_column_names[9:11])
data <- merged_df[, new_order]

print(colnames(data))

#Are there any duplicated gene names?
data$Gene.names %>% duplicated() %>% any()

# Make unique names using the annotation in the "Gene.names" column as primary names and the annotation in "Protein.IDs" as name for those that do not have an gene name.
data_unique <- make_unique(data, "Gene.names", "Protein.IDs", delim = ";")

# Generate a SummarizedExperiment object using an experimental design
LFQ_columns <- grep("LFQ.", colnames(data_unique)) # get LFQ column numbers

# Prepare the metadata for DEP analysis
experimental_design <- data.frame(
  label = colnames(filtered_count),
  condition = meta$Condition,
  replicate = NA  # Initialize replicate column with NA
)

# Assign replicate numbers within each condition
experimental_design <- experimental_design %>%
  group_by(condition) %>%
  mutate(replicate = row_number()) %>%
  ungroup()

# Set row names
row.names(experimental_design) <- experimental_design$label

# Ensure the row names of experimental_design are unique
experimental_design <- as.data.frame(experimental_design)
rownames(experimental_design) <- make.unique(rownames(experimental_design))

# Print the experimental design to verify
print(experimental_design)

# Create the SummarizedExperiment Object
# This will allow DEP to use the data for further analysis and visualization
data_se <- make_se(data_unique, LFQ_columns, experimental_design)

```
## Protein Coverage & filtrer on missing values
```{r Protein Coverage}
# Plot a barplot of the protein identification overlap between samples
plot_frequency(data_se)
plot_numbers(data_se)
plot_coverage(data_se)

# Filter for proteins that are identified in all replicates of at least one condition 
# Commented out as we have already performed filtrering manually in the first step, which unlike the terminal samples, will be used here. 
#data_filt <- filter_missval(data_se, thr = 0)
#plot_frequency(data_filt)

```
## Normalizaiton
```{r Normalization}
#Check un-normalized data
plot_normalization(data_se)

#VSN-normalization
data_se_norm <- normalize_vsn(data_se)

#Plot VSN-norm data
meanSdPlot(data_se_norm, rank = TRUE)
plot_normalization(data_se_norm)

###Verdict: After variance stabilisation, the median (a reasonable estimator of the standard deviation of feature level data conditional on the mean) is approximately a horizontal line.
```
### Impute data for missing values
```{r Imputation for Missing Values}
# Plot a heatmap of proteins with missing values
plot_missval(data_se_norm)

# Plot intensity distributions and cumulative fraction of proteins with and without missing values
plot_detect(data_se_norm)

# Typically, missing values in proteomics data are "Missing Not At Random" (MNAR),
# meaning proteins with missing values often have lower intensities and are close to the detection limit.
# For MNAR data, appropriate imputation methods include left-censored imputation techniques such as:
# - Quantile Regression-based Left-Censored (QRILC)
# - Random draws from a left-shifted distribution ("MinProb" or "man")

# Impute missing data using random draws from a Gaussian distribution centered around a minimal value (for MNAR)
data_imp_MinProb <- impute(data_se_norm, fun = "MinProb", q = 0.01) 

# Impute missing data using random draws from a manually defined left-shifted Gaussian distribution (for MNAR)
data_imp_man <- impute( data_se_norm, fun = "man", shift = 1.8, scale = 0.3) 


# Impute missing data using Quantile Regression Imputation of Left-Censored Data 
data_imp_qrilc <- impute( data_se_norm, fun = "QRILC") 

# Plot intensity distributions before and after imputation
# This plot helps assess the effectiveness of each imputation method by visualizing the changes in intensity distributions.
plot_imputation( data_se_norm, data_imp_MinProb, data_imp_man, data_imp_qrilc)

### Verdict: After visual inspection, it appears that the MinProb handles the MNAR nature of the data best. and will be used downstream. 
```

## Differential abundance analysis using DEP
```{r DEP differential abundance analyisis}
# Note: This analysis is intended as an extra quality control (QC) step.
# The main differential abundance analysis is performed using the `limma` package due to the more complex study design.
#Set contrasts
con <- c("RA_Control_4months_vs_RA_Sham_4months", "RA_Metformin_4months_vs_RA_Control_4months")

# Perform differential analysis using the specified contrasts - best on non-imputed data, honestly
data_diff <- test_diff(data_imp_qrilc, type = "manual", test = con)

# Denote significant proteins based on user defined cutoffs
dep <- add_rejections(data_diff, alpha = 0.05, lfc = log2(0))

# Generate a long data.frame
df_long <- get_df_long(dep)
df_wide <- get_df_wide(dep)

```

# MDS-plot
```{r}
# Transform raw count data and remove NA values
logCounts <- log2(count + 1)  # Add 1 to avoid log(0) issues
logCounts_noNA <- na.omit(logCounts)

# Create DGEList object and define the design matrix
annot_reordered <- annot[match(rownames(logCounts_noNA), annot$Genes), ]
d <- DGEList(counts = logCounts_noNA, genes = annot_reordered, samples = meta)
design <- model.matrix(~0 + Condition, data = d$samples)

# 1. MDS Plot for Raw Data
mds_raw <- plotMDS(logCounts_noNA, plot = FALSE)
mds_plot_raw <- aamisc::ggMDS(mds = mds_raw, meta = d$samples, color.by = "Group", shape.by = "Timepoint", legend.position = "right", text.by = "Horse", text.size = 1.5) +
  scale_color_manual(values = publication_colors) +
  labs(title = "MDS: Raw Data", x = "MDS Dimension 1", y = "MDS Dimension 2") +
  theme(legend.title = element_text(face = "bold"), plot.title = element_text(face = "bold", hjust = 0.5))

# 2. MDS Plot for Data Adjusted by Blocking for Horse
logCounts_blocked <- removeBatchEffect(logCounts_noNA, batch = as.factor(d$samples$Horse), design = design)
mds_blocked <- plotMDS(logCounts_blocked, plot = FALSE)
mds_plot_blocked <- aamisc::ggMDS(mds = mds_blocked, meta = d$samples, color.by = "Group", shape.by = "Timepoint", legend.position = "right", text.by = "Horse", text.size = 1.5) +
  scale_color_manual(values = publication_colors) +
  labs(title = "MDS: Blocked for Horse", x = "MDS Dimension 1", y = "MDS Dimension 2") +
  theme(legend.title = element_text(face = "bold"), plot.title = element_text(face = "bold", hjust = 0.5))


# Display the plots
print(mds_plot_raw)
print(mds_plot_blocked)
```


# Checking histograms and save/load imputations
```{r Intensity-Histograms, fig.height=5, fig.width=10}
# Histograms will be generated for four datasets:
# 1. `normalized_unimputed`: Normalized but not imputed data.
# 2. `imputed_data_MinProb`: Data imputed using the "MinProb" method.
# 3. `imputed_data_qrilc`: Data imputed using the "QRILC" method.
# 4. `unfiltered_count`: Raw log-transformed counts after initial filtering.

# Extract the assay data from data_se_norm (normalized_unimputed)
normalized_unimputed <- as.data.frame(assay(data_se_norm))
colnames(normalized_unimputed) <- colnames(filtered_count)
rownames(normalized_unimputed) <- rownames(data_se_norm)

# Extract the assay data from data_imp_MinProb (imputed)
imputed_data_MinProb <- as.data.frame(assay(data_imp_MinProb))
colnames(imputed_data_MinProb) <- colnames(filtered_count)
rownames(imputed_data_MinProb) <- rownames(data_se_norm)

# Extract the assay data from data_imp_qrilc
imputed_data_qrilc <- as.data.frame(assay(data_imp_qrilc))
colnames(imputed_data_qrilc) <- colnames(filtered_count)
rownames(imputed_data_qrilc) <- rownames(data_se_norm)

# Extract the assay data from data_imp_man
imputed_data_man <- as.data.frame(assay(data_imp_man))
colnames(imputed_data_man) <- colnames(filtered_count)
rownames(imputed_data_man) <- rownames(data_se_norm)

# Plot histogram for normalized data
par(mfrow = c(1, 4))
hist(as.vector(as.matrix(normalized_unimputed)), breaks = 50, main = "Normalized Data", xlab = "Intensity")
hist(as.vector(as.matrix(imputed_data_MinProb)), breaks = 50, main = "MinProb Imputed Data", xlab = "Intensity")
hist(as.vector(as.matrix(imputed_data_qrilc)), breaks = 50, main = "QRILC Imputed Data", xlab = "Intensity")
hist(as.vector(as.matrix(filtered_count)), breaks = 50, main = "Unfiltered Data", xlab = "Intensity")

# Define the output folder path
output_folder <- "../../../../Timecourse/analysis/01_dge/output/"

# Function to save a matrix with row names as a separate column
save_matrix <- function(matrix, file_path) {
  # Create a data frame from the matrix, including row names as a column
  matrix_df <- as.data.frame(matrix)
  matrix_df$GeneName <- rownames(matrix)
  fwrite(matrix_df, file = file_path, sep = "\t", row.names = FALSE)
}

# Function to load a matrix and restore row names
load_matrix <- function(file_path) {
  matrix_df <- fread(file_path, data.table = FALSE)
  rownames(matrix_df) <- matrix_df$GeneName
  matrix_df$GeneName <- NULL
  return(as.matrix(matrix_df))  # Convert back to a matrix
}

# Save the matrices
 # save_matrix(normalized_unimputed, paste0(output_folder, "normalized_unimputed.tsv"))
 # save_matrix(imputed_data_MinProb, paste0(output_folder, "imputed_data_MinProb.tsv"))
 # save_matrix(imputed_data_qrilc, paste0(output_folder, "imputed_data_qrilc.tsv"))

# Load the matrices in the future
normalized_unimputed <- load_matrix(paste0(output_folder, "normalized_unimputed.tsv"))
imputed_data_MinProb <- load_matrix(paste0(output_folder, "imputed_data_MinProb.tsv"))
imputed_data_qrilc <- load_matrix(paste0(output_folder, "imputed_data_qrilc.tsv"))


```

# Differential Abundance Analysis
## Limma without SVA
```{r limma, fig.height=10, fig.width=10}
# Define the design matrix
design <- model.matrix(~ 0 + Condition, d$samples)
colnames(design) <- gsub("Condition", "", colnames(design))  # Clean column names

# Define contrasts for comparisons of interest
con <- makeContrasts(
  Metformin_vs_AF_RA = RA_Metformin_4months - RA_Control_4months,
  AF_vs_Sham_RA = RA_Control_4months - RA_Sham_4months,
  Terminal_vs_Baseline_Control = RA_Control_4months - RA_Control_Baseline,
  Terminal_vs_Baseline_Metformin = RA_Metformin_4months - RA_Metformin_Baseline,
  Diff_Treatment = (RA_Metformin_4months - RA_Metformin_Baseline) - (RA_Control_4months - RA_Control_Baseline),
  Diff_Disease = (RA_Control_4months - RA_Control_Baseline) - (RA_Sham_4months - RA_Sham_Baseline),
  Baseline_Difference_Metf_vs_AF = RA_Metformin_Baseline - RA_Control_Baseline,
  Baseline_Difference_AF_vs_Sham = RA_Control_Baseline - RA_Sham_Baseline,
  levels = design)
con


# Estimate correlation due to repeated measures (blocking for Horse)
corfit <- duplicateCorrelation(imputed_data_MinProb, design, block = as.factor(d$samples$Horse))
cat("Estimated consensus correlation:", corfit$consensus.correlation, "\n")

# Fit the linear model
fit <- lmFit(imputed_data_MinProb, design, block = as.factor(d$samples$Horse), correlation = corfit$consensus.correlation)
rownames(fit$coefficients) <- rownames(imputed_data_MinProb)  # Retain row names for mapping

# Apply contrasts and empirical Bayes moderation
fit.contrast <- contrasts.fit(fit, contrasts = con)
fit.contrast <- eBayes(fit.contrast, robust = TRUE, trend = TRUE)

# Extract Differential Gene Expression (DGE) results
res <- list()  # List to store DGE results for each contrast
for (contrast in colnames(con)) {
  res_tmp <- topTable(fit.contrast, coef = contrast, adjust.method = "BH", number = Inf)
  res_tmp <- res_tmp[!is.na(res_tmp$t), ]  # Remove rows with NA values
  res_tmp$Contrast <- contrast  # Add contrast identifier
  res[[contrast]] <- res_tmp  # Store results
}

# Combine results across all contrasts into a single data frame
res_all <- do.call(rbind, res)

# Map Gene Names for easier interpretation (optional)
res_all$GeneName <- sapply(seq_len(nrow(res_all)), function(i) {
  gsub(paste0("^", res_all$Contrast[i], "\\."), "", rownames(res_all)[i])
})

# Split results for easier access/output
res_split <- split(res_all, res_all$Contrast)

# Visualize P-value Distributions
for (contrast in names(res_split)) {
  p_values <- res_split[[contrast]]$P.Value
  ggplot(data = data.frame(P.Value = p_values), aes(x = P.Value)) +
    geom_histogram(bins = 50, color = "black", fill = "lightblue") +
    theme_minimal() +
    labs(
      title = paste("P-value Histogram for", contrast),
      x = "P-value",
      y = "Frequency"
    ) +
    xlim(0, 1)  # Set x-axis limits between 0 and 1
  print(last_plot())
}

# VERDICT: Rising hill in P-value histogram detected (e.g. metformin_vs_AF_RA)
# Comment: A rising hill in the P-value histogram may indicate a systematic batch effect
# or a missing covariate that was not included in the initial design matrix.

cat("Detected potential systematic effects (rising hill in P-value histogram). Proceeding with SVA for adjustment...\n")
```



## Limma with SVA
```{r}
# In this workflow, SVA is used to remove hidden variance, and a blocking factor 
# accounts for variance introduced by repeated measures (e.g., two samples from the same horse).

# Extract biological condition information
condition <- d$samples$Condition  # Specify the biological condition

# Apply SVA to Adjust for Hidden Confounders
## Full model including condition
mod <- model.matrix(~ condition, data = d$samples) 

## Null model excluding biological information
mod0 <- model.matrix(~ 1, data = d$samples)

# Define the design matrix for downstream analysis
# Exclude intercept for simpler contrast definitions in lmFit
design <- model.matrix(~ 0 + condition, data = d$samples)

# Estimate the number of surrogate variables
n.sv <- num.sv(imputed_data_MinProb, mod, method = "be")  
cat("Number of surrogate variables estimated:", n.sv, "\n")

# Run SVA to estimate surrogate variables
svobj <- sva(imputed_data_MinProb, mod, mod0, n.sv = n.sv)

# Test on WSVA
wsva(y = imputed_data_MinProb, design = design, plot = TRUE, n.sv = n.sv) # Also Finds 8 surrogate variables

# Visualize Surrogate Variables to Ensure No Biological Information is Captured
# Prepare SV data for plotting
sv_data <- as.data.frame(svobj$sv)
colnames(sv_data) <- paste0("SV", seq_len(ncol(svobj$sv)))
sv_data <- cbind(d$samples, sv_data)

# Generate pairwise scatter plots of surrogate variables
sv_plots <- list()  # Store plots
sv_cols <- colnames(sv_data)[grep("^SV", colnames(sv_data))]

for (i in seq_along(sv_cols)) {
  for (j in seq_along(sv_cols)) {
    if (i < j) {  # Plot each pair only once
      sv_plots[[paste0("SV", i, "_SV", j)]] <- ggplot(sv_data, aes_string(x = sv_cols[i], y = sv_cols[j], 
                                                                          color = "Group", shape = "Timepoint")) +
        geom_point(size = 3, alpha = 0.8) +
        theme_minimal() +
        labs(title = paste("Surrogate Variables:", sv_cols[i], "vs", sv_cols[j]),
             x = paste("Surrogate Variable", i),
             y = paste("Surrogate Variable", j))
    }
  }
}

# Print all scatter plots for manual inspection
for (plot_name in names(sv_plots)) {
  print(sv_plots[[plot_name]])
}
cat("None of the surrogate variables captured variability related to disease group.\n")


# Incorporate Surrogate Variables into the Design Matrix for downstream analysis
modSv <- cbind(design, svobj$sv)

# Run duplicateCorrelation to estimate correlation between repeated samples (blocking by horse)
corfit <- duplicateCorrelation(imputed_data_MinProb, modSv, block = as.factor(d$samples$Horse))
cat("Consensus correlation for repeated measures:", corfit$consensus.correlation, "\n") # 0.1

# Fit the linear model with limma, accounting for repeated measures
fit <- lmFit(imputed_data_MinProb, modSv, block = as.factor(d$samples$Horse), correlation = corfit$consensus.correlation)
cat("Consensus correlation for repeated measures:", corfit$consensus.correlation, "\n") # 0.09

# Ensure column names in the design matrix are syntactically valid
colnames(modSv) <- make.names(colnames(modSv))

# Define contrasts with the updated column names
con <- makeContrasts(
  Metformin_vs_AF_RA = conditionRA_Metformin_4months - conditionRA_Control_4months,
  AF_vs_Sham_RA = conditionRA_Control_4months - conditionRA_Sham_4months,
  Terminal_vs_Baseline_Control = conditionRA_Control_4months - conditionRA_Control_Baseline,
  Terminal_vs_Baseline_Metformin = conditionRA_Metformin_4months - conditionRA_Metformin_Baseline,
  Diff_Treatment = (conditionRA_Metformin_4months - conditionRA_Metformin_Baseline) - (conditionRA_Control_4months - conditionRA_Control_Baseline),
  Diff_Disease = (conditionRA_Control_4months - conditionRA_Control_Baseline) - (conditionRA_Sham_4months - conditionRA_Sham_Baseline),
  Baseline_Difference_Metf_vs_AF = conditionRA_Metformin_Baseline - conditionRA_Control_Baseline,
  Baseline_Difference_AF_vs_Sham = conditionRA_Control_Baseline - conditionRA_Sham_Baseline,
  levels = modSv)
con

# Apply contrasts and run eBayes
fit <- contrasts.fit(fit, con)
fit <- eBayes(fit, robust = TRUE, trend = TRUE)

# Extract DGE results using the BH method for FDR correction
res <- list()  # List to store DGE results
for (i in colnames(con)) {
  res_tmp <- topTable(fit, coef = i, adjust.method = "BH", number = Inf)  # Get top table results
  res_tmp <- res_tmp[!is.na(res_tmp$t), ]  # Remove rows with NA values
  res_tmp$Contrast <- i #TODO: replaced this part >>> rep(i, nrow(res_tmp))  # Store the contrast name
  res[[i]] <- res_tmp  # Add to the results list
  
  # Print the number of differentially expressed genes based on adjusted p-values
  n_adj_pval <- nrow(res_tmp[res_tmp$adj.P.Val < 0.05, ])
  print(paste('Number of differentially expressed genes for', i, 'based on adjusted p-value (BH) =', n_adj_pval))
}

# Combine all results into a single data frame
res_all <- do.call(rbind, res)

# Map Gene Names Manually
res_all$GeneName <- sapply(seq_len(nrow(res_all)), function(i) {
  gsub(paste0("^", res_all$Contrast[i], "\\."), "", rownames(res_all)[i])
})

# Split results by contrast for easier output
res_split <- split(res_all, res_all$Contrast)

# Optionally, save the results to files
 openxlsx::write.xlsx(x = res_split, file = "../../../../Timecourse/analysis/01_dge/output/dge_results.xlsx", asTable = TRUE)
 data.table::fwrite(x = res_all, file = "../../../../Timecourse/analysis/01_dge/output/dge_results.tsv.gz", sep = "\t")

# Visualize Results with P-value Histograms
for (contrast in names(res_split)) {
  p_values <- res_split[[contrast]]$P.Value
  ggplot(data = data.frame(P.Value = p_values), aes(x = P.Value)) +
    geom_histogram(breaks = seq(0, 1, by = 0.05), color = "black", fill = "lightblue") +
    theme_minimal() +
    labs(title = paste("P-value Histogram for", contrast),
         x = "P-value",
         y = "Frequency") +
    xlim(0, 1)  # Set x-axis limits
  print(last_plot())
}


```


### Volcano plots
```{r volcano_plots, fig.height=10, fig.width=10}
volcano_plots <- list()
for (i in names(res)){
  volcano_plots[[i]] <- ggVolcano(x = res[[i]], 
                                  fdr = 0.05,
                                  fdr.column = "adj.P.Val", 
                                  pvalue.column = "P.Value", 
                                  logFC = 0, 
                                  logFC.column = "logFC", 
                                  text.size = 2) + 
    theme_bw(base_size = 10) + 
    ggtitle(i)
}

patchwork::wrap_plots(volcano_plots, ncol = 3)
```

## Volcano Plot for Publicaiton
```{r Volcano Plots for Publicaiton}
library(ggrepel)

# Create a named vector for ENSEMBL to Genes mapping
ensembl_to_Genes <- setNames(annot_reordered$Genes, annot_reordered$ENSEMBL)

# Map ENSEMBL IDs to Gene Names in the `res` list
for (contrast_name in names(res)) {
  # Ensure the dataframe has ENSEMBL IDs as rownames
  if (!"ENSEMBL" %in% colnames(res[[contrast_name]])) {
    res[[contrast_name]]$ENSEMBL <- rownames(res[[contrast_name]])
  }
  
  # Map Gene Names using the annotation
  res[[contrast_name]]$Genes <- ensembl_to_Genes[res[[contrast_name]]$ENSEMBL]
  
  # Replace NA values in Genes with ENSEMBL IDs (to ensure plotting works even if some gene names are missing)
  res[[contrast_name]]$Genes[is.na(res[[contrast_name]]$Genes)] <- res[[contrast_name]]$ENSEMBL[is.na(res[[contrast_name]]$Genes)]
}

# Load the volcano plot helper function
source("volcano_helpers.R")

# Create lists for volcano plots with and without labels
volcano_plots_no_labels <- list()
volcano_plots_with_labels <- list()

# Iterate over each contrast and create volcano plots
for (contrast_name in names(res)) {
  # Ensure the Genes column is present for labeling
  if (!"Genes" %in% colnames(res[[contrast_name]])) {
    res[[contrast_name]]$Genes <- sapply(rownames(res[[contrast_name]]), function(x) gsub(".*_", "", x))
  }
  
  # Generate volcano plots using the helper function
  volcano_plots <- create_custom_volcano_plot(
    df = res[[contrast_name]],
    logFC_col = "logFC",
    pvalue_col = "P.Value",
    adj_pvalue_col = "adj.P.Val",
    contrast_name = contrast_name,
    fc_cutoff = 0,  # Set fold-change cutoff for significance
    pvalue_cutoff = 0.05,  # Set p-value cutoff
    save_plot = TRUE, 
    output_path = "../output/",  # Adjust output path if needed
    show_labels = TRUE  # Generate both labeled and unlabeled plots
  )
  
  # Store the plots
  volcano_plots_no_labels[[contrast_name]] <- volcano_plots$No_Labels
  volcano_plots_with_labels[[contrast_name]] <- volcano_plots$With_Labels
}

# Combine and display volcano plots without labels
combined_volcano_no_labels <- patchwork::wrap_plots(volcano_plots_no_labels, ncol = 3)

# Combine and display volcano plots with labels
combined_volcano_with_labels <- patchwork::wrap_plots(volcano_plots_with_labels, ncol = 3)

# Display the combined volcano plots
print(combined_volcano_no_labels)
print(combined_volcano_with_labels)

# Print individual volcano plots with labels for key contrasts
print(volcano_plots_with_labels[["Diff_Treatment"]])
print(volcano_plots_with_labels[["Diff_Disease"]])

# ggsave("../output/volcano_Diff_Treatment_for_figure.png", (volcano_plots_with_labels[["Diff_Treatment"]]), 
#        dpi = 600, width = 4, height = 3, units = "in")



```
# Plotting One 

# Understanding Treatment Direction and Plotting Protein Abundance
```{r}
# Understanding LogFC for "Diff_Treatment"
# Positive LogFC indicates:
# 1) Metformin group shows a relatively higher level compared to the control group.
# 2) This can occur if:
#    a) Metformin increases and control decreases.
#    b) Both increase, but metformin shows a greater increase.
#    c) Both decrease, but metformin shows a smaller decrease.

# Negative LogFC indicates:
# 1) Metformin group shows a relatively lower level compared to the control group.
# 2) This can occur if:
#    a) Metformin decreases and control increases.
#    b) Both decrease, but metformin shows a greater decrease.
#    c) Both increase, but metformin shows a smaller increase.

# Load ggpubr for enhanced visualization
library(ggpubr)

# Step 1: Define the function to create a violin plot with individual points and mean line
plot_protein_counts <- function(protein_of_interest) {
  # Check if the protein is present in the dataset
  if (protein_of_interest %in% rownames(data_se_norm)) {
    # Extract the normalized counts for the protein
    protein_counts <- assay(data_se_norm)[protein_of_interest,]
    
    # Create a data frame for plotting
    protein_df <- data.frame(
      SampleID = colnames(data_se_norm), # Extract sample IDs
      Count = protein_counts,            # Protein counts
      Condition = meta$Condition         # Experimental conditions
    )
    
    # Generate violin plot with jitter points and mean line
    p <- ggplot(protein_df, aes(x = Condition, y = Count, fill = Condition)) +
      geom_violin(trim = FALSE, alpha = 0.5) +                        # Violin plot
      geom_jitter(width = 0.2, size = 2, alpha = 0.7) +               # Add individual points
      stat_summary(fun = mean, geom = "crossbar", width = 0.5, fatten = 2, color = "red") +  # Mean line
      labs(
        title = paste("Violin plot of normalized counts for", protein_of_interest),  # Plot title
        x = "Condition", y = "Normalized Abundance"                                  # Axis labels
      ) +
      theme_pubr() +                                                  # Apply a clean theme
      scale_fill_brewer(palette = "Set3")                             # Color palette

    print(p)  # Display the plot
  } else {
    # Output message if protein is not found
    cat("The protein", protein_of_interest, "is not present in the dataset.\n")
  }
}

# Step 2: Visualize selected proteins with significant treatment effects to understand, why it is upregulated and downregulated (see comment in beginning of chunk)

# A) Electron Transport Chain Genes - negatively regulated (blue) in "Diff_Treatment"
plot_protein_counts("NDUFA6")   # Associated with metformin in studies related to Aortic Aneurysms, increases less in metformin group
plot_protein_counts("ATP5F1C")  # Important candidate gene for treatment effects, small decrease in metformin group
plot_protein_counts("KARS1")    # Downregulated in response to treatment 

# B) Proteasome Proteins - negatively regulated (blue) in "Diff_Treatment"
plot_protein_counts("PSMC5")    # Protein linked to proteasome function
plot_protein_counts("PSMC4")    # Another candidate for proteasome-associated mechanisms
plot_protein_counts("PSMD11")   # Related to proteasome degradation processes

# C) Heat Shock Proteins (Hsp90 Family) - negatively regulated (blue) in "Diff_Treatment"
plot_protein_counts("SUGT1")    # Chaperone activity protein
plot_protein_counts("HSP90AA1") # Hsp90 protein linked to stress response
plot_protein_counts("DYNC1H1")  # Motor protein involved in cellular transport

# D) Detoxification of Reactive Oxygen Species (ROS) - positively regulated (red) in "Diff_Treatment"
plot_protein_counts("TXNRD2")   # Key enzyme in ROS detoxification
plot_protein_counts("TXN")      # Thioredoxin, involved in redox regulation
plot_protein_counts("SOD3")     # Superoxide dismutase, a primary ROS scavenger

# Additional Proteins of Interest
plot_protein_counts("DDAH1")    # Dimethylarginine Dimethylaminohydrolase 1
plot_protein_counts("COQ8A")    # Coenzyme Q8 homolog
plot_protein_counts("RICTOR")   # Component of mTOR complex
plot_protein_counts("YWHAE")    # 14-3-3 protein epsilon, signaling protein
plot_protein_counts("TXNDC5")   # Protein disulfide isomerase, ROS response

plot_protein_counts("GNAI2")


```

### Focus on GNAI2
```{r}
library(ggpubr)

# Define the function to create a violin plot with individual points and mean line
plot_protein_counts <- function(protein_of_interest) {
  # Check if the protein is present in the dataset
  if (protein_of_interest %in% rownames(data_se_norm)) {
    # Extract the normalized counts for the protein
    protein_counts <- assay(data_se_norm)[protein_of_interest,]
    
    # Create a data frame for plotting
    protein_df <- data.frame(
      SampleID = colnames(data_se_norm), # Extract sample IDs
      Count = protein_counts,            # Protein counts
      Condition = meta$Condition         # Experimental conditions
    )
    
    # Generate violin plot with jitter points and mean line
    p <- ggplot(protein_df, aes(x = Condition, y = Count, fill = Condition)) +
      geom_violin(trim = FALSE, alpha = 0.7, color = "black") +       # Violin plot with border
      geom_jitter(width = 0.15, size = 1.5, alpha = 0.6, color = "black") +  # Individual points
      stat_summary(fun = mean, geom = "crossbar", width = 0.5, fatten = 2, color = "darkred") +  # Mean line
      labs(
        title = paste("Normalized Protein Counts for", protein_of_interest),  # Plot title
        x = "Condition", y = "Normalized Abundance"                           # Axis labels
      ) +
      theme_pubr() +                                                          # Apply a clean, publication-ready theme
      scale_fill_brewer(palette = "Set3") +                                   # Use a color palette with enough colors
      theme(
        plot.title = element_text(size = 14, face = "bold", hjust = 0.5),     # Centered and bold title
        axis.title = element_text(size = 12, face = "bold"),                  # Bold axis titles
        axis.text = element_text(size = 10, color = "black"),                 # Custom axis text
        legend.position = "none"                                              # Remove legend
      )
    
    # Print the plot
    print(p)
  } else {
    # Output message if the protein is not found
    cat("The protein", protein_of_interest, "is not present in the dataset.\n")
  }
}

# Plot the protein counts for "GNAI2"
plot_protein_counts("GNAI2")
```

# Session Info
```{r session_info}
sessionInfo()
```
---
title: "Differential Abundance Analysis"
author: "Simon Haugaard"
date: "`r Sys.Date()`"
output:output: 
  html_document:
    toc: true
    toc_float: true
    toc_collapsed: true
    toc_depth: 3
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Required R libraries
```{r library}
if (!require("pacman")) install.packages("pacman")
pacman::p_load("edgeR")
pacman::p_load("readr")
pacman::p_load("readxl")
pacman::p_load("biomaRt")
pacman::p_load("magrittr")
pacman::p_load("tibble")
pacman::p_load("stringr")
pacman::p_load("ggplot2")
pacman::p_load("data.table")
pacman::p_load("ggplot2", "patchwork")
pacman::p_load("openxlsx")
pacman::p_load("pheatmap")
library(dplyr)
library(missForest)
library(RColorBrewer)
library(limma)
library(DEqMS)
library(preprocessCore)
library(DEP)
library(SummarizedExperiment)
library(Metrics)
library(fdrtool)
library(aamisc)
# Install and load custom libraries if not already present
# Uncomment the following lines if installing from archived packages or GitHub
# pacman::p_load("qvalue", "rain", "limma", "devtools")
# url <- "https://cran.r-project.org/src/contrib/Archive/HarmonicRegression/HarmonicRegression_1.0.tar.gz"
# pkgFile <- "HarmonicRegression_1.0.tar.gz"
# download.file(url = url, destfile = pkgFile)
# install.packages(pkgs=pkgFile, type="source", repos=NULL)
# file.remove(pkgFile)
# pacman::p_load_gh("altintasali/aamisc")  # Load `aamisc` package from GitHub repository

# Set color palette for publication visuals
publication_colors <- c("Control" = "#285291",    # Blue color for Control group
                        "Metformin" = "#7C1516",  # Red color for Metformin group
                        "Sham" = "#9B9B9B")       # Grey color for Sham group

```
# Load and Filter Proteomics Data
```{r read_data}
# Define file paths for proteomics data, metadata, and gene annotations
count_file <- "../../../data/count/report.unique_genes_matrix.tsv"
meta_file <- "../../../data/metadata/meta_proteomics.xlsx"
geneinfo_file <- "../../../data/gene_annotation/horse_gene_annotation.tsv.gz"

# 1. Read the Proteomics Count Data
count <- readr::read_delim(count_file)

# 2. Read Metadata
meta <- readxl::read_excel(meta_file)

# 3. Clean Count Data
# Remove any unnecessary blank columns created during MS processing
count <- count %>% select(-matches("D:\\\\Mass_spectrometry\\\\Raw_data\\\\Joakim\\\\Simon Horse second run2\\\\10A_RA11_1_24830.d"))

# 4. Load and Clean Gene Annotation Data
geneinfo <- fread(geneinfo_file)  # Load gene annotation
# Rename columns and remove duplicates
setnames(geneinfo, old = names(geneinfo), new = c("ENSEMBL", "ENSEMBLv", "Description_detailed", "Chr", "Start", "End", "Strand", "GENENAME", "ENTREZID", "Description"))
geneinfo <- geneinfo %>%
  select(-ENSEMBLv, -Description_detailed) %>%  # Remove unnecessary columns
  distinct(ENSEMBL, .keep_all = TRUE)            # Remove duplicates based on ENSEMBL

# 5. Merge Gene Annotations with Count Data
annot <- merge(count[, "Genes", drop = FALSE], geneinfo, by.x = "Genes", by.y = "GENENAME", all.x = TRUE)

# 6. Set Row Names for Count Data
count <- count %>%
  remove_rownames() %>%
  column_to_rownames(var = "Genes")  # Set "Genes" column as row names for easier subsetting

# Clean sample names to match metadata
cleaned_names <- gsub("D:\\\\Mass_spectrometry\\\\Raw_data\\\\Joakim\\\\Simon Horse second run2\\\\|_.*", "", colnames(count))
colnames(count) <- cleaned_names
meta$`Sample ID` <- cleaned_names

# 7. Remove Low-Quality Samples from Count and Meta
samples_to_remove <- c("25C", "12A", "22A", "19A")  # Specify samples to remove
count <- count[, !colnames(count) %in% samples_to_remove]
meta <- meta %>% filter(!`Sample ID` %in% samples_to_remove)

# 8. Subset Meta and Count to Include Only Terminal Samples
valid_conditions <- c("LA_Metformin_4months", "LA_Control_4months", "RA_Metformin_4months", "RA_Control_4months", "LA_Sham_4months", "RA_Sham_4months")
meta <- meta %>% filter(Condition %in% valid_conditions)
count <- count[, colnames(count) %in% meta$`Sample ID`]

# 9. Calculate Number of Proteins in Each Sample Before Filtering
num_proteins <- colSums(!is.na(count))  # Count non-NA values (proteins) per sample
num_proteins <- num_proteins[meta$`Sample ID`]  # Match order with metadata

# Define color scheme for groups based on publication color palette
KUalt <- c("#7C1516", "#285291", "#434343", "#999999")
group_colors <- setNames(KUalt[1:length(unique(meta$Group))], unique(meta$Group))
bar_colors <- group_colors[meta$Group]

# Plot: Number of Proteins in Each Sample Before Filtering
par(mfrow = c(1, 1))  # Reset plot layout
barplot(num_proteins, 
        main = "Number of Proteins in Each Sample\nBefore Filtering",
        xlab = "Sample",
        ylab = "Number of Proteins",
        col = bar_colors,
        border = "black",
        ylim = c(0, 2500),
        las = 2)  # Rotate x-axis labels

# Print Total Number of Proteins Before Filtering
cat("Total number of proteins before filtering:", max(num_proteins), "\n")

# 10. Identify and Remove Genes with Less Than Three Valid Values in Any Condition
invalid_genes <- unique(unlist(lapply(unique(meta$Condition), function(condition) {
  condition_columns <- meta$`Sample ID`[meta$Condition == condition]
  condition_count <- count[, condition_columns, drop = FALSE]
  rownames(condition_count)[rowSums(!is.na(condition_count)) < 3]
})))

# Remove Invalid Genes from Count Data
filtered_count <- count[!rownames(count) %in% invalid_genes, ]

# 11. Calculate Number of Proteins in Each Sample After Filtering
num_proteins_after <- colSums(!is.na(filtered_count))
num_proteins_after <- num_proteins_after[meta$`Sample ID`]  # Ensure matching order with metadata

# Plot Settings for Before and After Comparison
par(mfrow = c(1, 2))  # Set plot layout to 1 row and 2 columns

# Plot 1: Number of Proteins Before Filtering
barplot(num_proteins, 
        main = "Number of Proteins in Each Sample\nBefore Filtering",
        xlab = "Sample",
        ylab = "Number of Proteins",
        col = bar_colors,
        border = "black",
        ylim = c(0, 2500),
        las = 2)

# Plot 2: Number of Proteins After Filtering
barplot(num_proteins_after, 
        main = "Number of Proteins in Each Sample\nAfter Filtering",
        xlab = "Sample",
        ylab = "Number of Proteins",
        col = bar_colors,
        border = "black",
        ylim = c(0, 2500),
        las = 2)

# Print Total and Average Number of Proteins Before and After Filtering
cat("Total number of proteins before filtering:", max(num_proteins), "\n")
cat("Average number of proteins before filtering:", mean(num_proteins), "\n")
cat("Total number of proteins after filtering:", max(num_proteins_after), "\n")
cat("Average number of proteins after filtering:", mean(num_proteins_after), "\n")

```
# DEP-package  https://bioconductor.org/packages/release/bioc/vignettes/DEP/inst/doc/DEP.html
## Generate a SummarizedExperiment object
```{r DEP - create SE object}
# Define the raw count data as `unfiltered_count`
unfiltered_count <- count

# Step 1: Create annotation columns for the DEP package, using actual data if available
# If you don't have annotation data, these can remain as NA placeholders.
proxy_columns <- c("Protein.IDs", "Majority.protein.IDs", "Protein.names", "Gene.names", 
                   "Fasta.headers", "Peptides", "Razor...unique.peptides", "Unique.peptides", 
                   "Only.identified.by.site", "Reverse", "Potential.contaminant")

# Create a data frame with NA values for proxy columns and rownames from `unfiltered_count`
proxy_df <- data.frame(matrix(NA, nrow = nrow(unfiltered_count), ncol = length(proxy_columns)))
colnames(proxy_df) <- proxy_columns

# Assign the row names of `unfiltered_count` to the first few proxy columns to have a base
proxy_df[, 1:4] <- lapply(1:4, function(i) rownames(unfiltered_count))

# Step 2: Merge proxy annotations with LFQ data and rename LFQ columns to match DEP format
merged_df <- cbind(proxy_df, unfiltered_count)
colnames(merged_df)[12:ncol(merged_df)] <- paste0("LFQ.intensity.", colnames(unfiltered_count))

# Step 3: Rearrange columns to have LFQ intensities adjacent to annotation columns
lfq_columns <- grep("^LFQ.intensity", colnames(merged_df), value = TRUE)  # Find LFQ columns
rearranged_columns <- c(proxy_columns[1:8], lfq_columns, proxy_columns[9:11])
data <- merged_df[, rearranged_columns]

# Check for duplicated gene names (important for SE object creation)
if (any(duplicated(data$Gene.names))) {
  message("Warning: There are duplicated gene names in the dataset.")
}

# Step 4: Use `make_unique` to generate unique identifiers for each protein entry
# Using "Gene.names" as primary names and "Protein.IDs" as backup identifiers for uniqueness
data_unique <- make_unique(data, "Gene.names", "Protein.IDs", delim = ";")

# Step 5: Create an experimental design data frame
# Define LFQ intensity columns and set up the experimental design structure
LFQ_columns <- grep("LFQ.", colnames(data_unique))  # Get column numbers for LFQ intensities

# Generate an experimental design based on the metadata (`meta`) from the earlier step
experimental_design <- data.frame(
  label = colnames(unfiltered_count),    # Column names from unfiltered data as labels
  condition = meta$Condition,            # Condition information from metadata
  replicate = NA                         # Initialize a placeholder column for replicates
)

# Assign replicate numbers within each condition group
experimental_design <- experimental_design %>%
  group_by(condition) %>%
  mutate(replicate = row_number()) %>%  # Assign replicate numbers within each condition
  ungroup()

# Ensure row names of the experimental design match the column names of `data_unique`
row.names(experimental_design) <- experimental_design$label

# Print experimental design for verification
print(experimental_design)

# Step 6: Generate the SummarizedExperiment object using the `make_se` function from DEP
# This function requires unique identifiers for rows and an experimental design matrix
data_se <- make_se(data_unique, LFQ_columns, experimental_design)

```

## Protein Coverage and filtrering
```{r Protein Coverage}
# Plot Frequency of Identified Proteins Across Samples
plot_frequency(data_se)

# Note: No additional filtering is performed here as the initial filtering was conducted manually before creating the SE object
# Visualizes the number of proteins identified in each sample, providing insight into sample quality.
plot_numbers(data_se)

# Displays the overlap in protein identifications across all samples, which helps assess batch effects or discrepancies.
plot_coverage(data_se)

# Filter Proteins Based on Missing Values Across Replicates
# Filters for proteins that are identified in all replicates of at least one condition.
# This reduces the dataset to proteins with consistent detection, improving downstream analysis reliability.
# Set `thr = 0` to filter out proteins with missing values in all replicates.
data_filt <- filter_missval(data_se, thr = 0)

# Visualize the Frequency of Identified Proteins After Filtering
# Check how the distribution of protein frequency has changed after filtering out proteins with missing values.
plot_frequency(data_filt)

# Visualize the Number of Proteins Identified Per Sample After Filtering
plot_numbers(data_filt)

# Visualize Protein Identification Coverage Between Samples After Filtering
plot_coverage(data_filt)

```
## Normalizaiton
```{r Normalization}
#Check un-normalized data
plot_normalization(data_filt)

# Apply Variance-Stabilizing Normalization (VSN)
# Normalize the filtered data to stabilize variance across the range of intensities.
# VSN is commonly used for proteomics data to handle high dynamic range and heteroscedasticity.
data_filt_norm <- normalize_vsn(data_filt)

# Plot VSN-Normalized Data
# After normalization, this plot helps assess whether the variance has been stabilized.
# A successful normalization will show that the mean-variance relationship is approximately constant.
meanSdPlot(data_filt_norm, rank = TRUE)
plot_normalization(data_filt_norm)

# Verdict: The mean-SD plot shows that after variance stabilization,  the median (which serves as a reasonable estimator of the standard deviation of feature-level data
# conditional on the mean) is approximately a horizontal line. This indicates that the normalization has successfully stabilized the variance, and the data is suitable for downstream differential analysis.
```
### Impute data for missing values
```{r Imputation for Missing Values}
# Visualize Proteins with Missing Values
plot_missval(data_filt_norm)

# Visualize Intensity Distributions and Cumulative Fraction of Proteins
plot_detect(data_filt_norm)

# Typically, missing values in proteomics data are "Missing Not At Random" (MNAR),
# meaning proteins with missing values often have lower intensities and are close to the detection limit.
# For MNAR data, appropriate imputation methods include left-censored imputation techniques such as:
# - Quantile Regression-based Left-Censored (QRILC)
# - Random draws from a left-shifted distribution ("MinProb" or "man")

# Impute missing data using random draws from a Gaussian distribution centered around a minimal value (for MNAR)
data_imp_MinProb <- impute(data_filt_norm, fun = "MinProb", q = 0.01) 

# Impute missing data using random draws from a manually defined left-shifted Gaussian distribution (for MNAR)
data_imp_man <- impute( data_filt_norm, fun = "man", shift = 1.8, scale = 0.3) 

# Impute missing data using Quantile Regression Imputation of Left-Censored Data 
# QRILC is particularly useful when missing values are assumed to be low or below the detection limit.
data_imp_qrilc <- impute( data_filt_norm, fun = "QRILC") 

# Plot intensity distributions before and after imputation
# This plot helps assess the effectiveness of each imputation method by visualizing the changes in intensity distributions.
plot_imputation( data_filt_norm, data_imp_MinProb, data_imp_man, data_imp_qrilc)

### Verdict: After visual inspection, it appears that the QRILC method (`data_imp_qrilc`) handles the MNAR nature of the data best. and will be used downstream. 
```

## Differential abundance analysis using DEP
```{r DEP differential abundance analyisis}
# Note: This analysis is intended as an extra quality control (QC) step.
# The main differential abundance analysis is performed using the `limma` package due to the more complex study design.
# Here, DEP is used to test for differential protein abundance in a straightforward manner.

# Define contrasts for differential analysis
# The contrasts compare different conditions (e.g., Metformin vs Control) within each region (RA/LA).
contrasts <- c("RA_Control_4months_vs_RA_Sham_4months", 
               "LA_Control_4months_vs_LA_Sham_4months", 
               "RA_Metformin_4months_vs_RA_Control_4months", 
               "LA_Metformin_4months_vs_LA_Control_4months")

# Perform Differential Abundance Analysis Using the Specified Contrasts
# This analysis is based on the imputed data (`data_imp_qrilc`) and compares protein abundance between the conditions.
# Since the imputation may affect the statistical results, it's best to cross-check results with non-imputed data if feasible.
data_diff <- test_diff(data_imp_qrilc, type = "manual", test = contrasts)

# Denote Significant Proteins Based on User-Defined Cutoffs
# Mark proteins as significant if they meet the defined criteria: FDR (alpha) < 0.05 and log fold change (lfc) > log2(0).
# Setting lfc = log2(0) indicates we are testing for any change, regardless of direction or magnitude.
dep <- add_rejections(data_diff, alpha = 0.05, lfc = log2(0))

```

## Volcano plots and DAE using DEP
```{r DEP - Volacano}
# Plot Volcano Plots for Each Contrast
# Volcano plots show the relationship between fold change and significance for each contrast.
# Proteins with large fold changes and high significance (low p-values) are highlighted.
plot_volcano(dep, contrast = "RA_Control_4months_vs_RA_Sham_4months", label_size = 2, add_names = TRUE)
plot_volcano(dep, contrast = "LA_Control_4months_vs_LA_Sham_4months", label_size = 2, add_names = TRUE)
plot_volcano(dep, contrast = "RA_Metformin_4months_vs_RA_Control_4months", label_size = 2, add_names = TRUE)
plot_volcano(dep, contrast = "LA_Metformin_4months_vs_LA_Control_4months", label_size = 2, add_names = TRUE)

# Plot Frequency of Significant Proteins Across Conditions
# This plot summarizes the number of significant proteins detected for each condition,
# providing an overview of the differential abundance results.
plot_cond(dep)

# Generate and View Results Table
# Extract results from the DEP object into a structured data frame for further analysis.
data_results <- get_results(dep)

# Display the First Few Rows of the Results Table (optional)
head(data_results)

# Calculate and Print the Number of Significant Proteins
# This step helps evaluate the number of differentially abundant proteins detected at the given cutoffs.
num_significant_proteins <- data_results %>% filter(significant) %>% nrow()
cat("Number of significant proteins detected across all contrasts:", num_significant_proteins, "\n")

```
# MDS-plots on non-imputed data
```{r MDS plots}
# Log-Transformation of Count Data
# Apply log2 transformation to raw count data to stabilize variance and make the data more suitable for MDS.
logCounts <- log2(count)

# Remove NA Values for PCA and MDS
# MDS cannot handle missing values, so we remove rows with any NA values before generating plots.
logCounts_noNA <- na.omit(logCounts)

meta$Group <- factor(meta$Group, levels = names(publication_colors))

# Make DGE list and define design
annot_reordered <- annot[match(rownames(logCounts_noNA), annot$Genes), ]
d <- DGEList(counts = logCounts_noNA, genes = annot_reordered, samples = meta)
design <- model.matrix(~0 + Condition, d$samples)

# Remove batch effect, related to each horse contributing with two samples (RA and LA) - "paired design"
logCounts_batchRemoved <- removeBatchEffect(logCounts_noNA, 
                                            batch = as.factor(d$samples$Horse), 
                                            design = design)

# Plot MDS
mds <- plotMDS(logCounts_batchRemoved, plot = FALSE)

dims <- list(p1 = c(1,2), p2 = c(1,3), p3 = c(2,3), p4 = c(1,4))
mds_plot <- list()

# Without labels
for (i in seq_along(dims)){
  mds_plot[[i]] <- aamisc::ggMDS(mds = mds,
                                 meta = d$samples, 
                                 dim = dims[[i]], 
                                 color.by = "Group", 
                                 shape.by = "Region",
                                 legend.position = "right"
                                 ) + 
                  scale_color_manual(values = publication_colors)
}

plot1 <- patchwork::wrap_plots(mds_plot, ncol = 2) + patchwork::plot_layout(guides = 'collect')

# With labels
for (i in seq_along(dims)){
  mds_plot[[i]] <- aamisc::ggMDS(mds = mds,
                                 meta = d$samples, 
                                 dim = dims[[i]], 
                                 color.by = "Group", 
                                 shape.by = "Region",
                                 legend.position = "right",
                                 text.by = "Horse",
                                 text.size = 1.5
                                 ) + 
                  scale_color_manual(values = publication_colors)
}

plot2 <- patchwork::wrap_plots(mds_plot, ncol = 2) + patchwork::plot_layout(guides = 'collect')

# Display the plots
print(plot1)
print(plot2)


```

# Checking histograms of normalized-unimputed (data_filt_norm), imputed (data_imp_MinProb) and raw log-counts (filtred_counts) before limma
```{r Intensity-Histograms, fig.height=5, fig.width=10}
# Prepare Data for Histogram Visualization
# Histograms will be generated for four datasets:
# 1. `normalized_unimputed`: Normalized but not imputed data.
# 2. `imputed_data_MinProb`: Data imputed using the "MinProb" method.
# 3. `imputed_data_qrilc`: Data imputed using the "QRILC" method.
# 4. `unfiltered_count`: Raw log-transformed counts after initial filtering.

# Extract the assay data from data_filt_norm (normalized_unimputed)
normalized_unimputed <- as.data.frame(assay(data_filt_norm))
colnames(normalized_unimputed) <- colnames(unfiltered_count)
rownames(normalized_unimputed) <- rownames(data_filt_norm)

# Extract the assay data from data_imp_MinProb (imputed)
imputed_data_MinProb <- as.data.frame(assay(data_imp_MinProb))
colnames(imputed_data_MinProb) <- colnames(unfiltered_count)
rownames(imputed_data_MinProb) <- rownames(data_filt_norm)

# Extract the assay data from data_imp_qrilc
imputed_data_qrilc <- as.data.frame(assay(data_imp_qrilc))
colnames(imputed_data_qrilc) <- colnames(unfiltered_count)
rownames(imputed_data_qrilc) <- rownames(data_filt_norm)

# Plot histogram for normalized data
par(mfrow = c(1, 4))
hist(as.vector(as.matrix(normalized_unimputed)), breaks = 50, main = "Normalized Data", xlab = "Intensity")
hist(as.vector(as.matrix(imputed_data_MinProb)), breaks = 50, main = "MinProb Imputed Data", xlab = "Intensity")
hist(as.vector(as.matrix(imputed_data_qrilc)), breaks = 50, main = "QRILC Imputed Data", xlab = "Intensity")
hist(as.vector(as.matrix(unfiltered_count)), breaks = 50, main = "Filtered Data", xlab = "Intensity")

# Comment on the Histograms
# The histograms provide an overview of the intensity distributions at various stages of data preprocessing.
# Moving on, we will use the `QRILC` imputed data (`data_imp_qrilc`) for downstream analysis as it best addresses missing values.
```
#Export normalized, filtrered and imputed data for multiomics data integration
```{r Export Data}
# Define the mapping from old names to new names
rename_mapping <- c(
  "1B" = "M1_RA",  "1C" = "M1_LA",
  "2B" = "M2_RA",  "2C" = "M2_LA",
  "3B" = "M3_RA",  "3C" = "M3_LA",
  "4B" = "M4_RA",  "4C" = "M4_LA",
  "5B" = "M5_RA",  "5C" = "M5_LA",
  "6B" = "M6_RA",  "6C" = "M6_LA",
  "7B" = "M7_RA",  "7C" = "M7_LA",
  "8B" = "M8_RA",  "8C" = "M8_LA",
  "9B" = "M9_RA",  "9C" = "M9_LA",
  "10B" = "M10_RA", "10C" = "M10_LA",
  "11B" = "M11_RA", "11C" = "M11_LA",
  "12B" = "M12_RA", "12C" = "M12_LA",
  "13B" = "M13_RA", "13C" = "M13_LA",
  "14B" = "M14_RA", "14C" = "M14_LA",
  "15B" = "M15_RA", "15C" = "M15_LA",
  "16B" = "M16_RA", "16C" = "M16_LA",
  "17B" = "M17_RA", "17C" = "M17_LA",
  "18B" = "M18_RA", "18C" = "M18_LA",
  "19B" = "M19_RA", "19C" = "M19_LA",
  "20B" = "M20_RA", "20C" = "M20_LA",
  "22B" = "M22_RA", "22C" = "M22_LA",
  "23B" = "M23_RA", "23C" = "M23_LA",
  "24B" = "M24_RA", "24C" = "M24_LA",
  "25B" = "M25_RA"
)


# Rename the columns using the mapping
norm_proteomics <- imputed_data_qrilc %>% rename_with(~ rename_mapping[.x], everything())
norm_proteomics <- as.data.frame(norm_proteomics)

#Save the Normalized Proteomics Data for Integration
# Save the renamed and imputed proteomics data as a text file for further integration with other omics data.
# Note: The line below is commented out to avoid overwriting files unintentionally.
# write.table(norm_proteomics, file="../../../../../Proteomics/Terminal/analysis/01_dge/output/proteomics_data.txt", sep="\t", col.names=NA, quote=FALSE)

# Step 4: Save the QRILC Imputed Data as an RDS Object for Further Analysis
# Save the `data_imp_qrilc` object as an RDS file for use in downstream applications.
# This is useful for restoring the exact imputed data structure later without re-running the imputation process.
# saveRDS(data_imp_qrilc, file = "../../../../../Proteomics/Terminal/analysis/01_dge/output/data_imp_qrilc.rds")

```

# Differential Abundance Analysis using Limma
```{r limma, fig.height=10, fig.width=10}
#Set the design
design <- model.matrix(~0 + Condition , d$samples)
colnames(design) <- gsub("Condition", "", colnames(design))

con <- makeContrasts(AF_vs_Sham_RA = RA_Control_4months - RA_Sham_4months,
                     AF_vs_Sham_LA = LA_Control_4months - LA_Sham_4months,
                     Metformin_vs_AF_RA = RA_Metformin_4months - RA_Control_4months,
                     Metformin_vs_AF_LA = LA_Metformin_4months - LA_Control_4months,
                     RA_vs_LA_Sham = RA_Sham_4months - LA_Sham_4months,
                     RA_vs_LA_AF = RA_Control_4months - LA_Control_4months,
                     RA_vs_LA_Metformin = RA_Metformin_4months - LA_Metformin_4months,
                     InteractionEffect = (RA_Sham_4months - RA_Control_4months) - (LA_Sham_4months - LA_Control_4months),
                     AverageDiseaseEffect = (RA_Control_4months + LA_Control_4months)/2 - (LA_Sham_4months + RA_Sham_4months)/2,
                     AverageTreatmentEffect = (RA_Metformin_4months + LA_Metformin_4months)/2 - (LA_Control_4months + RA_Control_4months)/2,
                     AverageRegionEffect = (RA_Sham_4months + RA_Control_4months)/2 - (LA_Sham_4months + LA_Control_4months)/2,
                     levels = design)
con


#Run limma whilst blocking for "horse"/Estimate Correlation due to Repeated Measures (Blocking for "Horse")
# Correlation within horses is accounted for using `duplicateCorrelation`.
corfit <- duplicateCorrelation(imputed_data_qrilc, design, block = as.factor(d$samples$Horse))
fit <- lmFit(imputed_data_qrilc, design, block = as.factor(d$samples$Horse), correlation = corfit$consensus.correlation)
rownames(fit$coefficients) <- rownames(imputed_data_qrilc)  # Retain row names for downstream mapping

# Obtain DGE results with FDR correction using fdrtool
res <- list() # list for DGE results
for (i in colnames(con)) {
  fit.contrast <- contrasts.fit(fit, contrasts = con)
  fit.contrast <- eBayes(fit.contrast, robust = TRUE, trend = TRUE)  # Fit contrasts and apply Empirical Bayes moderation
  res_tmp <- topTable(fit.contrast, coef = i, number = Inf) 
  res_tmp <- res_tmp[!is.na(res_tmp$t), ]  # Remove NA values
  
  # Apply FDR correction using fdrtool
  fdr_res <- fdrtool(res_tmp$t, plot = FALSE, verbose = FALSE)
  res_tmp$qval <- fdr_res$qval # FDR-corrected q-values
  res_tmp$lfdr <- fdr_res$lfdr # Local FDR values
  res_tmp$Contrast <- rep(i, nrow(res_tmp))  # Store contrast identifier
  res[[i]] <- data.frame(res_tmp)  # Append results to the list
  
  ## We use the fdrtool package for FDR correction to align with the DEP package and ensure consistency in our proteomics analysis workflow. This method models the distribution of test statistics directly, providing both q-values and local false discovery rates (lfdr) for a more refined control of type I error.
  
  # Print the number of differentially abundant genes
  n_qval <- res_tmp %>% filter(qval < 0.05) %>% nrow()
  n_adj_pval <- res_tmp %>% filter(adj.P.Val < 0.05) %>% nrow()
  print(paste('Number of differentially abundant genes for', i, 'based on q-value (FDR) =', n_qval))
  print(paste('Number of differentially abundant genes for', i, 'based on adjusted p-value =', n_adj_pval))
}
res_all <- do.call(rbind, res) # Combine results across all contrasts

# Map Gene Names Manually
res_all$GeneName <- sapply(seq_len(nrow(res_all)), function(i) {
  gsub(paste0("^", res_all$Contrast[i], "\\."), "", rownames(res_all)[i])
})
res_split <- split(res_all, res_all$Contrast) # Split the combined results based on contrast for easier output

# Create output Excel file
# Commented out 
# openxlsx::write.xlsx(x = res_split, file = "../../../../Terminal/analysis/01_dge/output/dge_results.xlsx", asTable = TRUE)

# Create output TSV file
# Commeneted out 
# data.table::fwrite(x = res_all, file = "../../../../Terminal/analysis/01_dge/output/dge_results.tsv.gz", sep = "\t")

```


### Volcano plots with P values
```{r volcano_plots, fig.height=10, fig.width=10}
volcano_plots <- list()
for (i in names(res)){
  volcano_plots[[i]] <- ggVolcano(x = res[[i]], 
                                  fdr = 0.05,
                                  fdr.column = "P.Value", 
                                  pvalue.column = "P.Value", 
                                  logFC = 0, 
                                  logFC.column = "logFC", 
                                  text.size = 2) + 
    theme_bw(base_size = 10) + 
    ggtitle(i)
}

patchwork::wrap_plots(volcano_plots, ncol = 3)

# Here, P-values are used rather than FDR values on the y-axis. In the manuscript figures, the y-axis has therefore been manually changed to reflect the actual used p-value. 

```